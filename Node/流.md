在`Node.js`中，流不仅是技术，而且也是关于性能和效率。

# 使用和创建流
## Buffering vs. Streaming
缓存讲的就是发起一个异步请求API，在`buff mode`下，所有的数据都被缓存在缓存中，在操作执行完后，通过回调，将所有数据传给调用方。
![buffering](./static/buffering.png)

而对于流式的方式来说，只要数据被产生了，就会直接传输给接收方，中间是无缝的。
![streaming](./static/streaming.png)


上述两个方式的主要区别在：
- 空间效率
- 时间效率

除了上述两个之外，`Node.js`的流还有一个额外的很重要的特性：`组合性`

## 空间效率
在老的版本的`Node.js`中，`V8`的`buffer`最大不能超过`0x3fffffff`字节（小于1GB）。下面拿文件压缩做例子。

使用`buffer`的版本：
```js
const fs = require('fs');
const zlib = require('zlib');

const file = process.argv[2];

fs.readFile(file, (err, buffer) => {
  zlib.gzip(buffer, (err, buffer) => {
    fs.writeFile(file + '.gz', buffer, err => {
      console.log(`File successfully compressed`);
    });
  });
});
```

此例子中，会发现`Node.js`的运行进程的内存消耗会持续增高，直到将整个文件读取完成，这就对运行机器的物理内存有一定要求。`另外一个情况就是，压缩大文件（超过4GB）时会失败。`

使用`stream`的版本：
```js
const fs = require('fs');
const zlib = require('zlib');

const file = process.argv[2];

fs.createReadStream(file)
  .pipe(zlib.createGzip())
  .pipe(fs.createWriteStream(file + '.gz'))
  .on('finish', () => console.log(`File successfully compressed`));
```

而使用基于`Stream`版本的压缩例子，整个运行期间，内存总量没有超过百兆。而且`对被压缩的文件的大小没有限制`。


## 时间效率
想象一个场景：本地要压缩一个文件并上传到远端的`HTTP`服务器，然后服务器解压缩后保存到服务器上的文件系统中。看下对比：
![compare](./static/compare.png)

可以看出，基于`Stream`的方式就是一个流水线，而基于`Buffer`的段落式的等待类型。

例子参考`gzipReceive.js`和`gzipSend.js`


## 可组合性
可组合性指的是在`管道化`中我们可以加入我们想要的处理流层，此层接收来自上一层的输入，然后将结果输出到下一层。比如在上一个例子，加入`加密层`：
```js
const crypto = require('crypto');

// ...
fs.createReadStream(file)
  .pipe(zlib.createGzip())
  .pipe(crypto.createCipher('aes192', 'a_shared_secret'))
  .pipe(req)
  .on('finish', () => console.log(`File successfully sent`));
```

在服务端进行相应的解密：
```js
const crypto = require('crypto');
// ...
const server = http.createServer((req, res) => {
// ...
req
  .pipe(crypto.createDecipher('aes192', 'a_shared_secret'))
  .pipe(zlib.createGunzip())
  .pipe(fs.createWriteStream(filename))
  .on('finish', () => { /* ... */ });
})
```


# 在不同的上下文中使用流，而不只是在`I/O`

# 基于流的异步控制流

# 管道化